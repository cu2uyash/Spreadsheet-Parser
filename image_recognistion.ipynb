{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image recognistion.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP9IlSoHaacsY8xTrseSioq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cu2uyash/Spreadsheet-Parser/blob/master/image_recognistion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DGVJi94hqtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from pathlib import Path"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUcbbUdEjMrL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0dae53f2-2d38-488b-d6bf-b8d3ce095709"
      },
      "source": [
        "# Loading the data  set # it returns 4 parameters the training and testing data with coressponding labels\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BblJU7UzjR1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3913f68a-78be-4448-936b-08551ab24c6b"
      },
      "source": [
        "#NN works best when input data are floating points are  values and are b/w 0 and 1 normally images are stored in form of pixels values b/w 0-255 so we convert it from integer to floating point values\n",
        "# Normalize data set to 0-to-1 range\n",
        "x_train =x_train.astype(\"float32\")\n",
        "x_test =x_test.astype(\"float32\")\n",
        "#now we scale the data so its between 0 and 1 that can be done by simply diving the data by max value that is 255 So this way data is normalized.\n",
        "# as x_train and x_test are numpy array it will divide every value of array with 255(For more detail refer to the concept of board-casting.)\n",
        "x_train =x_train/255\n",
        "x_test =x_test/255\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "# Our labels are single values from 0 to 9.\n",
        "# Instead, we want each label to be an array with on element set to 1 and and the rest set to 0.\n",
        "y_train =keras.utils.to_categorical(y_train, 10)\n",
        "y_test =keras.utils.to_categorical(y_test, 10)\n",
        "# Create a model and add layers\n",
        "#we will create a squential model it is called squential because we add layers in sequence and it automatically gets connected set by step\n",
        "model =Sequential()\n",
        "#we will add a convolutional layers as it work best on images for detection of various king of patterns in a image thr are tow types of convolutional layers 1D and 2D since we are working with images we will use 2D layer\n",
        "#the first parameter is how many diff filter each will be capable to detect one pattern in image next is size of window that will be used to get images tiles form the image thsi will split up the image in 3*3 window size while doing this if the window size is divisible of image size then fine or to get it done we can add padding to the image that is adding extra zeros to the image.\n",
        "#next is the activation function and since its the first layer we need to specify the input dimensions of image\n",
        "model.add(Conv2D(32,(3,3),padding=\"same\",activation='relu',input_shape=(32,32,3)))\n",
        "#to make model more efficient we will add more such convolutional layers\n",
        "model.add(Conv2D(32,(3,3),activation='relu'))\n",
        "#Max pooling is to scale down the o/p of Convolutional layers with higher values and throwing away the smaller ones this makes NN more efficient\n",
        "#The parameter we need to specify is the pool size that is it will make a matrix of 2*2 and select the largest value from them. keeping the matrix small with imp values\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#One problem with NN is they tend to memorise data instead of learning so to eliminate this we will add a dropout layer\n",
        "#we will randomly hrow up some data by cutting down some connection b/w layers\n",
        "#the only parameter we need to add is percntg of connection need to be cut\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#whenever we make tramsitional between a conv2D layer and dense layer we need to tell NN that we no longer working with 2D data for that we use flatten function\n",
        "model.add(Flatten())\n",
        "#In the below line of code we are adding a Dense layer with  512 node and WE are specifying a activation function\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.50))\n",
        "#for the output since we 10 diff objects so we will take 10 nodes and since the o/p will be of one object per image we will use softmax as a activation function\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "#As the model is built by adding diff layers the final step is to compile the model\n",
        "#here we need to specify  the loss fuction that is how much right or wrong your training is next we specify the optimizer\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam')\n",
        "# TO see how models looks like\n",
        "# Print a summary of the model\n",
        "model.summary()\n",
        "#train the model\n",
        "#to train the model we need to call model.fit()\n",
        "# we need to specify the training dataset and corresponding labels\n",
        "#next we need to pass batch size that is how many images we need to fit in during training set the number not too low not too high\n",
        "#then we need to specify number of epoch that is one pass through the total dataset\n",
        "#next we give the validation data that network has never seen\n",
        "#and to randomise data we set shuffle.\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=30,\n",
        "    validation_data=(x_test, y_test),\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Save neural network structure\n",
        "model_structure = model.to_json()\n",
        "f = Path(\"model_structure.json\")\n",
        "f.write_text(model_structure)\n",
        "\n",
        "# Save neural network's trained weights\n",
        "model.save_weights(\"model_weights.h5\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 232s 5ms/step - loss: 1.5687 - val_loss: 1.1975\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 243s 5ms/step - loss: 1.1590 - val_loss: 0.9802\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 243s 5ms/step - loss: 0.9784 - val_loss: 0.8479\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 235s 5ms/step - loss: 0.8726 - val_loss: 0.7915\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 241s 5ms/step - loss: 0.8035 - val_loss: 0.7257\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 238s 5ms/step - loss: 0.7506 - val_loss: 0.7172\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 239s 5ms/step - loss: 0.7057 - val_loss: 0.6825\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 241s 5ms/step - loss: 0.6708 - val_loss: 0.6934\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 241s 5ms/step - loss: 0.6437 - val_loss: 0.6909\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 231s 5ms/step - loss: 0.6104 - val_loss: 0.6695\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 238s 5ms/step - loss: 0.5892 - val_loss: 0.6199\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 235s 5ms/step - loss: 0.5638 - val_loss: 0.6677\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 237s 5ms/step - loss: 0.5441 - val_loss: 0.6308\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 231s 5ms/step - loss: 0.5238 - val_loss: 0.6371\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 234s 5ms/step - loss: 0.5161 - val_loss: 0.6633\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 244s 5ms/step - loss: 0.4945 - val_loss: 0.6223\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 240s 5ms/step - loss: 0.4810 - val_loss: 0.6280\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 232s 5ms/step - loss: 0.4632 - val_loss: 0.6205\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 235s 5ms/step - loss: 0.4561 - val_loss: 0.6298\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 236s 5ms/step - loss: 0.4446 - val_loss: 0.6142\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 230s 5ms/step - loss: 0.4385 - val_loss: 0.6375\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 228s 5ms/step - loss: 0.4302 - val_loss: 0.6448\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 229s 5ms/step - loss: 0.4217 - val_loss: 0.6287\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 236s 5ms/step - loss: 0.4132 - val_loss: 0.6382\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 231s 5ms/step - loss: 0.4150 - val_loss: 0.6220\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 227s 5ms/step - loss: 0.3935 - val_loss: 0.6394\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 230s 5ms/step - loss: 0.3886 - val_loss: 0.6672\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 235s 5ms/step - loss: 0.3831 - val_loss: 0.6211\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 234s 5ms/step - loss: 0.3832 - val_loss: 0.6413\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 229s 5ms/step - loss: 0.3676 - val_loss: 0.6530\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SA_ThjWkYY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2175d1e2-6abb-4ada-9615-6c18dd61ca6b"
      },
      "source": [
        "from keras.models import model_from_json\n",
        "from pathlib import Path\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# These are the CIFAR10 class labels from the training data (in order from 0 to 9)\n",
        "class_labels = [\n",
        "    \"Plane\",\n",
        "    \"Car\",\n",
        "    \"Bird\",\n",
        "    \"Cat\",\n",
        "    \"Deer\",\n",
        "    \"Dog\",\n",
        "    \"Frog\",\n",
        "    \"Horse\",\n",
        "    \"Boat\",\n",
        "    \"Truck\"\n",
        "]\n",
        "\n",
        "# Load the json file that contains the model's structure\n",
        "#instead for building the neural network again we can direclty load the structure of NN and will be easier to use\n",
        "f = Path(\"model_structure.json\")\n",
        "#now we will read the file and store the structure in a variable\n",
        "model_structure = f.read_text()\n",
        "\n",
        "# Recreate the Keras model object from the json data\n",
        "#we can build the structure from json we can make use of below helper function from keras\n",
        "model = model_from_json(model_structure)\n",
        "\n",
        "# Re-load the model's trained weights\n",
        "#to restore the training as well we need to load the trained wghts\n",
        "\n",
        "model.load_weights(\"model_weights.h5\")\n",
        "\n",
        "# Load an image file to test, resizing it to 32x32 pixels as required by this model\n",
        "img = image.load_img(\"frog.png\", target_size=(32, 32))\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "image_to_test = image.img_to_array(img)\n",
        "\n",
        "# Add a fourth dimension to the image since Keras expects a list of images not a single image\n",
        "list_of_images = np.expand_dims(image_to_test, axis=0)\n",
        "\n",
        "# Make a prediction using the model\n",
        "results = model.predict(list_of_images)\n",
        "\n",
        "# Since we are only testing one image, we only need to check the first result\n",
        "single_result = results[0]\n",
        "\n",
        "# We will get a likelihood score for all 10 possible classes. Find out which class had the highest score.\n",
        "most_likely_class_index = int(np.argmax(single_result))\n",
        "class_likelihood = single_result[most_likely_class_index]\n",
        "\n",
        "# Get the name of the most likely class\n",
        "class_label = class_labels[most_likely_class_index]\n",
        "\n",
        "# Print the result\n",
        "print(\"This is image is a {} - Likelihood: {:2f}\".format(class_label, class_likelihood))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is image is a Frog - Likelihood: 1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}