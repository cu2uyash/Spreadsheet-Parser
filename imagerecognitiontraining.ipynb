{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP/RJwHEjGSF7Meh5UdvWdk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cu2uyash/Spreadsheet-Parser/blob/master/imagerecognitiontraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DGVJi94hqtw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6b2b446-abf1-4b2b-f9db-59f5b00e3ce0"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from pathlib import Path"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUcbbUdEjMrL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "656cadc4-f7cd-4154-ffd7-aa1d46d12e86"
      },
      "source": [
        "# Loading the data  set # it returns 4 parameters the training and testing data with coressponding labels\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BblJU7UzjR1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "d1d1b7f0-b666-4c6c-aa94-3c45db1e82ee"
      },
      "source": [
        "#NN works best when input data are floating points are  values and are b/w 0 and 1 normally images are stored in form of pixels values b/w 0-255 so we convert it from integer to floating point values\n",
        "# Normalize data set to 0-to-1 range\n",
        "x_train =x_train.astype(\"float32\")\n",
        "x_test =x_test.astype(\"float32\")\n",
        "#now we scale the data so its between 0 and 1 that can be done by simply diving the data by max value that is 255 So this way data is normalized.\n",
        "# as x_train and x_test are numpy array it will divide every value of array with 255(For more detail refer to the concept of board-casting.)\n",
        "x_train =x_train/255\n",
        "x_test =x_test/255\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "# Our labels are single values from 0 to 9.\n",
        "# Instead, we want each label to be an array with on element set to 1 and and the rest set to 0.\n",
        "y_train =keras.utils.to_categorical(y_train, 10)\n",
        "y_test =keras.utils.to_categorical(y_test, 10)\n",
        "# Create a model and add layers\n",
        "#we will create a squential model it is called squential because we add layers in sequence and it automatically gets connected set by step\n",
        "model =Sequential()\n",
        "#we will add a convolutional layers as it work best on images for detection of various king of patterns in a image thr are tow types of convolutional layers 1D and 2D since we are working with images we will use 2D layer\n",
        "#the first parameter is how many diff filter each will be capable to detect one pattern in image next is size of window that will be used to get images tiles form the image thsi will split up the image in 3*3 window size while doing this if the window size is divisible of image size then fine or to get it done we can add padding to the image that is adding extra zeros to the image.\n",
        "#next is the activation function and since its the first layer we need to specify the input dimensions of image\n",
        "model.add(Conv2D(32,(3,3),padding=\"same\",activation='relu',input_shape=(32,32,3)))\n",
        "#to make model more efficient we will add more such convolutional layers\n",
        "model.add(Conv2D(32,(3,3),activation='relu'))\n",
        "#Max pooling is to scale down the o/p of Convolutional layers with higher values and throwing away the smaller ones this makes NN more efficient\n",
        "#The parameter we need to specify is the pool size that is it will make a matrix of 2*2 and select the largest value from them. keeping the matrix small with imp values\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#One problem with NN is they tend to memorise data instead of learning so to eliminate this we will add a dropout layer\n",
        "#we will randomly hrow up some data by cutting down some connection b/w layers\n",
        "#the only parameter we need to add is percntg of connection need to be cut\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#whenever we make tramsitional between a conv2D layer and dense layer we need to tell NN that we no longer working with 2D data for that we use flatten function\n",
        "model.add(Flatten())\n",
        "#In the below line of code we are adding a Dense layer with  512 node and WE are specifying a activation function\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.50))\n",
        "#for the output since we 10 diff objects so we will take 10 nodes and since the o/p will be of one object per image we will use softmax as a activation function\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "#As the model is built by adding diff layers the final step is to compile the model\n",
        "#here we need to specify  the loss fuction that is how much right or wrong your training is next we specify the optimizer\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam')\n",
        "# TO see how models looks like\n",
        "# Print a summary of the model\n",
        "model.summary()\n",
        "#train the model\n",
        "#to train the model we need to call model.fit()\n",
        "# we need to specify the training dataset and corresponding labels\n",
        "#next we need to pass batch size that is how many images we need to fit in during training set the number not too low not too high\n",
        "#then we need to specify number of epoch that is one pass through the total dataset\n",
        "#next we give the validation data that network has never seen\n",
        "#and to randomise data we set shuffle.\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=30,\n",
        "    validation_data=(x_test, y_test),\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Save neural network structure\n",
        "model_structure = model.to_json()\n",
        "f = Path(\"model_structure.json\")\n",
        "f.write_text(model_structure)\n",
        "\n",
        "# Save neural network's trained weights\n",
        "model.save_weights(\"model_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "37504/50000 [=====================>........] - ETA: 55s - loss: 1.6626"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}